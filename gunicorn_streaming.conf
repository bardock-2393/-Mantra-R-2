# Gunicorn Configuration for High-Performance Streaming Uploads
# Production-ready settings for 2GB+ video processing

# === BINDING AND WORKERS ===

bind = "127.0.0.1:8000"
workers = 2                    # Fewer workers for memory-intensive AI tasks
worker_class = "gthread"       # Thread-based for I/O-bound upload tasks
threads = 8                    # 8 threads per worker for concurrent uploads

# === TIMEOUT SETTINGS (Critical for large uploads) ===

timeout = 3600                 # 1 hour timeout for large uploads
keepalive = 120               # Keep connections alive for resumable uploads
graceful_timeout = 30         # Graceful shutdown time

# === MEMORY AND PERFORMANCE ===

max_requests = 50             # Restart workers after 50 requests (memory management)
max_requests_jitter = 10      # Add randomness to avoid thundering herd
preload_app = True            # Preload app for better memory usage
worker_tmp_dir = "/dev/shm"   # Use shared memory for temporary files (if available)

# === LOGGING ===

accesslog = "logs/gunicorn_access.log"
errorlog = "logs/gunicorn_error.log"
loglevel = "info"
access_log_format = '%(h)s %(l)s %(u)s %(t)s "%(r)s" %(s)s %(b)s "%(f)s" "%(a)s" %(D)s'

# === SECURITY ===

limit_request_line = 8192     # Max size of HTTP request line
limit_request_fields = 100    # Max number of header fields
limit_request_field_size = 8192  # Max size of header field

# === PRODUCTION SETTINGS ===

# Process naming
proc_name = "ai_video_detective_streaming"

# Worker process management
worker_connections = 1000
max_requests_jitter = 50

# Enable stats
statsd_host = None  # Set to your StatsD server if available

# === DEVELOPMENT OVERRIDES ===
# Uncomment for development

# bind = "0.0.0.0:8000"
# workers = 1
# reload = True
# timeout = 600